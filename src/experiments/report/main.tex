% !TeX root = main.tex
\input{preamble}

\title{Project Final Report: Modeling and Generating Realistic Workloads}
\author{JianChen Zhao}
\email{jianchen.zhao@uwaterloo.ca}
\addbibresource{paperpile.bib}

\begin{document}

\begin{abstract}
% todo
\end{abstract}

\maketitle

\section{Introduction}

In today's dynamic and interconnected digital landscape, where user expectations for speed and reliability are higher than ever, workload testing is indispensable. For instance, Ticketmaster, a well-known ticket vendor, faced technical difficulties such as server crashes and increased latency during a pre-sale event for Taylor Swift's 2022 tour. Despite preregistrations for the event, their system faltered due to inadequate load testing \cite{Reuters2022-dc}. In contrast, during Prime Day 2023, Amazon handled an astounding number of requests, including 764 petabytes of EBS data transfer, over 15.35 trillion requests, 830 CloudTrail events, and 500 million CloudFront HTTP requests per minute. Amazon would not have achieved such a feat without rigorous load testing\cite{Barr2023-wr}.

As software systems become more complex and are deployed on increasingly diverse platforms, assessing their robustness under varying workloads becomes paramount. Large-scale software systems like cloud services are deeply embedded into today's economy. Many businesses's critical operations rely on such software. To illustrate, the global end-user spending in public cloud services is more than half a trillion USD in 2023\cite{UnknownUnknown-aj}. For operators of such large-scale software systems, a failure can result in significant financial loss and impact business worldwide\cite{LuuUnknown-mo}; Facebook, for example, lost an estimated 90 million USD to a 14-hour outage caused by misconfigured DNS\cite{AtlassianUnknown-sw}. Interestingly, such failures can not be attributed to functional bugs\cite{Weyuker2000-gw}. It is, therefore, crucial that systems are rigorously tested as a whole.

\subsection{Background}

Among the various system testing paradigms, load testing emerges as a critical aspect, focusing on the system's ability to handle different levels of expected user activity. This form of testing empirically guarantees that a software application can meet its performance objectives under realistic working conditions.

Load testing involves simulating different scenarios and conditions that mimic the actual usage patterns and demands the software may encounter in a production environment. Subjecting the system to \emph{workloads}, including typical and peak loads, reduces system failure risks while helping identify potential bottlenecks, vulnerabilities, or performance degradation that may not arise in functional tests \cite{Syer2017-ek, Shang2015-gj, Cohen2005-mn, Hassan2008-nj, Chen2016-bo}.

The most basic form of load testing consists of replaying the system against a manually collected dataset of user actions. This approach requires extensive tooling of the deployed system to capture the user actions and ample storage to accommodate the large number of workloads necessary to capture the variance in user actions. Many prior works have explored the automatically recovering workloads to work around these issues.

However, automatically generating workloads is no trivial task. There are two main challenges. First, the generated workload must be realistic. The action patterns in the workload must be representative of actual field observations. This property is essential to the usefulness of load testing. Testing on unrealistic data cannot ensure that the system under test can handle actual user actions. Second, real user actions have high variance; that is, there is a diverse number of action patterns in production environments. Hence, automatic workload generation techniques must balance the variance and representativeness of the recovered workload.

\subsection{Related Work}

Prior works on workload generation have explored automatically recovering workloads from various readily available sources, which are resampled for replay.

Many proposed approaches abstract away user behaviors in workload and only consider specific metrics. This reduces the information needed to be stored for replay. \cite{Shang2015-gj, Cohen2005-mn} use CPU usage metrics for high-level representation of user behaviors. Similarly, \cite{Haghdoost2017-bc, Yadwadkar2010-ml, Busch2015-yo, Seo2014-xv} characterize the load by the I/O usage, while \cite{Cortez2017-nc} looks at other system resource usage to model the workloads. While such coarse-grained approaches are efficient and easy to maintain, information about essential characteristics of the load might be lost.

As demonstrated in \cite{Cohen2005-mn}, more precise characterization of workloads may lead to better performance. \cite{Yadwadkar2010-ml} explored using a hidden Markov model to find patterns of user behaviors and found that only a small amount of data is required to construct an adequate model of the user behaviors.

To balance the granularity of the recovered workloads, \cite{Syer2017-ek, Vogele2018-zz, Summers2016-jj, Xi2011-ki, Hassan2008-nj} distinguishes different user behaviors by clustering user actions extracted from event logs or system traces. \cite{Chen2019-fu} adds to this approach by also considering sequences of user actions and their context, helping find more representative user behaviors without sacrificing the variance of the recovered workloads and introducing some adaptability to the approach. While this approach can achieve a good balance, it suffers from two problems. First, the approach clusters users based on their behaviors to sample actions and action sequences of a recovered workload using representative users. In effect, the diversity of the generated workload is restricted by the size of the source used to recover the initial workload. Second, event logs and traces are noisy. Actions are thus recovered by filtering on some user identifiers. However, those identifiers are not always present, and the recovered actions may be incomplete \cite{Zhao2023-nh}.

\subsection{Contributions}

To tackle the challenges above, we propose an extensible model of user behaviors based on a mixture of Hidden Markov Models (HMM) to allow the dynamic generation of workloads unconstrained by the size of the initial recovered workload. We evaluate our model and demonstrate its performance and generalizability. We also propose directions for future improvements.

\subsection{Organization}

We present our model in detail in \cref{sec:modeling_processes} while highlighting challenges in training such a model. We show in \cref{sec:approach} how it can be integrated to generate workloads dynamically. We evaluate it in \cref{sec:experimental_setup,sec:results}, and discuss tradeoffs and potential improvements in \cref{sec:discussion}. Finally, we conclude in \cref{sec:conclusion}.

\section{Modeling Event Logs}\label{sec:modeling_processes}

Event logs and system traces are discrete-time processes. Given time steps \(1, 2, ..., t, ..., \tau - 1, \tau\),  events \(y_t\) are observed according to an underlying process, that is, the control flow of a running software system.

\subsection{Control Flow Graph}

The control flow graph (CFG) of a program can be understood as the graphical representation of its state transitions at runtime. Nodes in this graph represent sequences of statements executed sequentially without branching except at the entry and exit statements. Edges represent the control flow and its branching between the basic blocks.

The CFG can also be seen as a description of the underlying process that produces outputs and, for our purposes, event logs and system traces. However, to get a complete picture of the production process, we need to compute the CFG for the whole program, or in other words, the interprocedural CFG (ICFG). Computing this ICFG is resource-intensive, impractical, and often outright impossible. It must thus be approximated\cite{Zhao2023-nh}.

\subsection{Hidden Markov Chains (HMM)}

\begin{figure}
    \caption{An example of a graph of the states of a process, with associated state transition probabilities. This graph is analogous to a control flow graph.}
    \label{fig:state_graph}
    \vspace{2ex}
    \begin{tikzpicture}[x=1pt,y=1pt]
        \node [box,circle] (a) at (135:72) {$a$};
        \node [box,circle] (b) at (015:72) {$b$};
        \node [box,circle] (c) at (255:72) {$c$};
        \draw [->,thick] (a) -- (b) node [midway,fill=white] {$\prob\pan{X_{t+1} = b \giv X_t = a}$};
        \draw [->,thick] (a) -- (c) node [midway,fill=white] {$\prob\pan{X_{t+1} = c \giv X_t = a}$};
        \draw [->,thick] (b) -- (c) node [midway,fill=white] {$\prob\pan{X_{t+1} = c \giv X_t = b}$};
    \end{tikzpicture}
\end{figure}

Instead of directly approximating an ICFG, we can fit a hidden Markov model (HMM) on a program's output to learn its states and transitions at runtime. In this approach, we do not require the use of source code. The learned graph, where nodes are states and edges are transitions, is an indirect approximation of the ICFG with respect to the output. That is, it models the process that generates the outputs.

A HMM \(\mu = (X, Y)\) consists of two stochastic processes: \(X = \{X_t : 0 \leq t \leq \tau\}\) is a Markov process that is not directly observable, hence hidden, and \(Y = \{Y_t : 0 \leq t \leq \tau\}\) that is directly observed. Each \(X_t\) only depends on the previous \(X_{t-1}\) and each \(Y_t\) only depends on \(X_t\).

For simplicity, we assume that \(X\) is ergodic; that is, the probability of getting from every state to every other state is non-zero. This assumption should hold in practice; for load testing, we are concerned with system states that are reoccurring and don't lead to the termination of the system.

\Cref{fig:hmm} shows a visualization of a HMM. At each time step, the state of the process transitions to a new state. We denote the set of all states as \(\mathcal{S}\). Along with every transition, an observation is emitted. We denote the set of all observations as \(\mathcal{O}\). At a given discrete time \(t\), suppose the hidden process is at a state \(i \in \mathcal{S}\). The probability of transitioning to a state \(j \in \mathcal{S}\) at time \(t+1\) is given by
\begin{equation}\label{eq:transition}
    \prob\pan{X_{t+1} = j \giv X_t = i} = a_{i,j}.
\end{equation}
At time \(t = 0\), the probability of being in a state \(i\) is given by the prior distribution with
\begin{equation}\label{eq:prior}
    \prob\pan{X_0 = i} = \pi_i.
\end{equation}
The probability of emitting, or equivalently, observing, the event \(k\) at time \(t\) when the state is \(i\) is
\begin{equation}\label{eq:emission}
    \prob\pan{Y_t = k \giv X_t = i} = b_{i,k}.
\end{equation}

A HMM intuitively models event logs and system traces. The process \(Y\) is the observed events, while the process \(X\) approximates the interprocedural control flow. The state transitions represent the branching in the control flow between statements that produce events. Because this abstraction does not consider the actual user inputs to the software system, the branching behavior of the program is captured by the probabilities \(a_{i,j}\).

Since, in a control flow of a program, a single statement should only be able to emit at most one type of event, it may be practical to set \(\mathcal{S} = \mathcal{O}\) and \(b_{i,k} = \delta(i,k)\) where \(\delta\) is the indicator function. However, we note that an ICFG is hard to approximate. Thus, it is more desirable to keep the set of hidden states \(\mathcal{S}\) flexible, as the set of observations is fixed to the actual observations in event logs and system traces.

\begin{figure}
    \caption{A diagram representing a HMM. \(y_1, y_2, ..., y_\tau\) are observations; they are emitted with probability \(\prob\pan{Y_t = y_t \giv X_t = x_t}\). \(x_t\) is the hidden state at time \(t\), where the next state is transitioned to with probability \(\prob\pan{X_{t + 1} = x_{t+1} \giv X_t = x_t}\)}
    \label{fig:hmm}
    \vspace{2ex}
    \begin{tikzpicture}[x=1pt,y=1pt]
        \matrix [column sep=10] {
            \node [box] (e1) {$y_1$}; & \node [box] (e2) {$y_2$}; & \node [box,draw=none] (da) {$\dots$}; & \node [box] (et) {$y_t$}; & \node [box,draw=none] (db) {$\dots$}; & \node [box] (etauprev) {$y_{\tau - 1}$}; & \node [box] (etau) {$y_\tau$}; \\
        };
        \node [box,circle,below=25 of et] (st) {$x_t$};
        \draw [->,thick] (e1) -- (e2);
        \draw [->,thick] (e2) -- (da);
        \draw [->,thick] (da) -- (et);
        \draw [->,thick] (et) -- (db);
        \draw [->,thick] (db) -- (etauprev);
        \draw [->,thick] (etauprev) -- (etau);
        \draw [->,thick] (st) -- (et) node[midway,right] {$\prob\pan{Y_t = y_t \giv X_t = x_t}$};
        \draw [->,thick] (st) to [loop,looseness=6,out=315,in=225] node[midway,below] {$\prob\pan{X_{t + 1} = x_{t+1} \giv X_t = x_t}$} (st);
    \end{tikzpicture}
\end{figure}

\subsection{Interleaved HMM}

While a single HMM can intuitively model a single process, A software system often comprises multiple processes. For example, a single system might run multiple programs, each utilizing multiple threads. Furthermore, event logs from each process may be collected and gathered in a centralized storage. 

Individual threads can also communicate with each other, possibly across different hardware. Thus, data flows across thread boundaries. In this case, processes may not be restricted to a single thread. Instead, it is more suitable to let the hidden states model the states of the data flow of the whole system.

Following this parallel computation paradigm, we can mix multiple HMMs. This mixture of HMMs can be encoded into a single HMM \cite{Minot2014-gn}. That is, markov models produces observation events into the same sequence, but at any time step, only one individual chain is allowed to transition, according to some random variable.

Consider the random variable \(X_t\) for a state at type \(t\). It can be defined as composition of states of \(m\) different HMMs \(\mu_k\) for \(1 \leq k \leq m\):
\begin{equation}
    X_t = \pan{S_{\mu_1,t}, S_{\mu_2,t}, ..., S_{\mu_m,t}, C_t}.
\end{equation}
\(C_t\) can be defined in different ways, including as an oberservation of another additional HMM; but for simplicity and intuition, we choose that
\begin{equation}
    \prob\pan{C_t = c} = \alpha_c
\end{equation}
At any time \(t\), only one chain is allowed to transition, dictated by the choice variable \(C_t\). The probability of the chain \(\mu\) to transition from state \(i\) to \(j\) is then
\begin{equation}
    \prob\pan{S_{\mu,t+1} = j \giv S_{\mu,t} = i, C_t = c_t} = \begin{cases}
        a_{\mu,i,j} & \text{if $c_t = \mu$,} \\
        \delta\pan{i, j} & \text{otherwise.} \\
    \end{cases}
\end{equation}
Then, \cref{eq:transition,eq:prior,eq:emission} are redefined as follows:
\begin{equation}
    \begin{multlined}
        \prob\pan{X_{t + 1} = x_{t+1} \giv X_t = x_t} = \\
        \alpha_{c_t}\prod_{\mu} \prob\pan{S_{\mu,t+1} = s_{\mu,t+1} \giv S_{\mu,t} = s_{\mu,t}, C_t = c_t},
    \end{multlined}
\end{equation}
\begin{equation}
    \prob\pan{X_0 = x} = \alpha_c \prod_\mu \pi_{\mu,s_\mu}
\end{equation}
\begin{equation}
    \prob\pan{Y_t = y \giv X_t = x} = b_{c,s_c,y}
\end{equation}

\section{Approach}\label{sec:approach}

We propose an automatic workload generation approach that leverages generative models and their unsupervised learning capabilities. In this approach, only a small set of user actions must be collected to train the model. Once fitted, the model can extrapolate realistic synthetic workloads with high entropy.

\subsection{Fitting the Model}

Consider a single HMM \(\mu\) with states \(1, 2, ...,n\) in \(S_\mu\). To fit this HMM on a hidden process, we can maximize the likelihood \(\mathcal{L}(\mu | \seq{y_t}_t) = p_\mu(\seq{y_t}_t)\) of \(\mu\) given observations from the hidden process \(\seq{y_t}_t = \seq{y_1, y_2, ..., y_t}\). Since an observation \(y_t\) is only dependant on the current state \(x_t\), we can write this probability like so:
\begin{equation}\label{eq:likelihood}
    p_\mu(\seq{y_t}_t) = \sum_{x_t} p_\mu(x_t, \seq{y_t}_t),
\end{equation}
where it can be demonstrated by recursively applying the chain rule that for \(1
\leq t \leq T\)
\begin{equation}
    \begin{multlined}
        p_\mu(x_t, \seq{y_t}_t) = \\
        p_\mu(y_t|x_t) \sum_{x_{t-1}} p_\mu(x_t|x_{t-1}) p_\mu(x_{t-1}, \seq{y_t}_{t-1}).
    \end{multlined}
\end{equation}
and with the base case
\begin{equation}\label{eq:max_likelihood}
    p_\mu(x_0, \seq{}) = p_\mu(x_0)
\end{equation}
\(p_\mu(y_t|x_t)\) is the emission probability of \(\mu\), \(p_\mu(x_t | x_t)\) is the transition probability and \(p_\mu(x_0)\) is the prior or stationary probability of the states. Then, the fitted model \(\hat{\mu}\) is one that maximizes \cref{eq:likelihood}
\begin{equation}
    \label{eq:argmax_observation}
    \hat{\mu} = \argmax_{\mu} p_\mu(\seq{y_t}_t).
\end{equation}

This recursive equation can be solved using the forward algorithm described in \cref{alg:forward}. The forward algorithm has space complexity \(O(n)\)  and time complexity \(O(nT)\) where \(n\) is the number of possible states and \(T\) is the length of the input sequence. In the context of interleaved HMM \(\mu\), there are \(K\) individual HMMs \(\mu_k\), the state of \(\mu\) must encode the states of all \(\mu_k\). Thus, no matter the encoding, the time and space complexity of the forward algorithm will be exponential with respect to \(K\). In fact, training the interleaved HMM is an intractable problem\cite{Landwehr2008-vw}.
\begin{algorithm}[H]
    \caption{The forward algorithm.}\label{alg:forward}
    \begin{algorithmic}[1]
        \Function{Forward}{$o_{1..T}$}
        \For{$i \gets 1 .. n$}
        \State $\alpha_i \gets \pi_i$
        \EndFor
        \For{$t \gets 1 .. T$}
        \For{$i \gets 1 .. n$}
        \State $\alpha_i \gets P(o_t|s_{i,t}) \sum_{s_{i, t-1}} P(s_{i, t} | s_{i, t-1}) \alpha_i$√ç
        \EndFor
        \EndFor
        \State \Return $\sum_{i} \alpha_i$
        \EndFunction
    \end{algorithmic}
\end{algorithm}

Since the forward algorithm's gradient can be automatically computed by Jax\cite{Bradbury2018-jz}, on which Flax is based, \cref{eq:argmax_observation} can be found using gradient descent. Specifically, I used the Adam\cite{Kingma2014-jj} optimizer on a synthetic dataset described in \cref{sec:dataset}. I implemented the forward algorithm in \(\log\) space for better numerical stability and thus the optimized loss is the negative log-likelihood:
\begin{equation}
    \label{eq:neg_log_likelihood}
    \argmin_{\mu} - \log P(y_{1..T} | \mu).
\end{equation}

\section{Experimental Setup}\label{sec:experimental_setup}

We have implemented an interleaved HMM using the Flax\cite{Heek2023-nl} framework.


\subsection{Research Questions}

\begin{researchquestions}
    \item\label{rq:performance} How does our approach perform for real workloads?
    \item\label{rq:ablation} How does the approach perform under different settings?
\end{researchquestions}

\subsection{Datasets}\label{sec:dataset}

\subsubsection{Apache James}

\subsubsection{OpenMRS}

\subsubsection{Google Borg Trace Version 2}

\section{Results}\label{sec:results}

\subsection*{\cref{rq:performance}: How does our approach perform for real workloads?}

\subsection*{\cref{rq:ablation}: How does our approach perform under different settings?}

\section{Discussion}\label{sec:discussion}

\subsection{Threats to Validity}

\subsubsection{Internal Validity}

\subsubsection{External Validity}

\subsubsection{Construct Validity}

\subsection{Future Work}

\section{Conclusion}\label{sec:conclusion}

\printbibliography

\end{document}